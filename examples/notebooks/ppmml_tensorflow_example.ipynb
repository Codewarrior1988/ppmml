{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import logging\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import shutil\n",
    "import tempfile\n",
    "import unittest\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.contrib.learn import LinearClassifier\n",
    "from tensorflow.contrib.learn import DNNClassifier\n",
    "from tensorflow.contrib.learn import RunConfig\n",
    "from tensorflow.contrib.layers import one_hot_column\n",
    "from tensorflow.contrib.layers import real_valued_column\n",
    "from tensorflow.contrib.layers import sparse_column_with_keys\n",
    "from tensorflow.contrib.layers.python.layers.feature_column import _OneHotColumn\n",
    "from tensorflow.contrib.layers.python.layers.feature_column import _RealValuedColumn\n",
    "from tensorflow.contrib.layers.python.layers.feature_column import _SparseColumnKeys\n",
    "from tensorflow.contrib.learn.python.learn.utils.input_fn_utils import InputFnOps\n",
    "\n",
    "from sklearn.datasets import load_iris\n",
    "\n",
    "import ppmml\n",
    "\n",
    "tf.logging.set_verbosity(tf.logging.INFO)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train iris data with tensorflow and export tensorflow model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def _export_tf_model(estimator, serving_input_fn, model_output_path):\n",
    "    \"\"\" export tensorflow model\n",
    "    \"\"\"\n",
    "    savemodel_dir = estimator.export_savedmodel(tempfile.mkdtemp(),\n",
    "        serving_input_fn = serving_input_fn, as_text = True)\n",
    "    savemodel_dir = savemodel_dir.decode(\"UTF-8\")\n",
    "\n",
    "    if(os.path.isdir(model_output_path)):\n",
    "        shutil.rmtree(model_output_path)\n",
    "    logging.info(\"moving model path from {} to {}\".format(savemodel_dir, model_output_path))\n",
    "    shutil.move(savemodel_dir, model_output_path)\n",
    "\n",
    "\n",
    "def _dnn_feature_columns(feature_columns):\n",
    "    \"\"\" generate dnn feature columns\n",
    "    \"\"\"\n",
    "    dnn_columns = []\n",
    "    for col in feature_columns:\n",
    "        dnn_col = real_valued_column(col, dtype = tf.float64)\n",
    "        if isinstance(col, _SparseColumnKeys):\n",
    "            dnn_columns.append(one_hot_column(dnn_col))\n",
    "        else:\n",
    "            dnn_columns.append(dnn_col)\n",
    "    return dnn_columns\n",
    "\n",
    "\n",
    "def _input_fn(df, cont_feature_columns, cat_feature_columns, label_column):\n",
    "    \"\"\" tensorflow estimator input function\n",
    "\n",
    "    Args:\n",
    "        df: pandas dataframe\n",
    "        cont_feature_columns: list of string, numeric column names\n",
    "        cat_feature_columns: list of string, category column names\n",
    "    \"\"\"\n",
    "    cont_features = {}\n",
    "    for col in cont_feature_columns:\n",
    "        cont_features[col] = \\\n",
    "            tf.constant(df[col].values, dtype = tf.float64, shape = [df[col].size, 1])\n",
    "\n",
    "    cat_features = {}\n",
    "    for col in cat_feature_columns:\n",
    "        cat_features[col] = \\\n",
    "            tf.constant(df[col].values, dtype = tf.string, shape = [df[col].size, 1])\n",
    "    features = dict(list(cont_features.items()) + list(cat_features.items()))\n",
    "    label = tf.constant(df[label_column].values, shape = [df[label_column].size, 1])\n",
    "    return features, label\n",
    "\n",
    "def _serving_input_fn(cont_feature_columns, cat_feature_columns):\n",
    "    \"\"\" tensorflow estimator serving input function\n",
    "\n",
    "    Args:\n",
    "        cont_feature_columns: list of string, numeric column names\n",
    "        cat_feature_columns: list of string, category column names\n",
    "    \"\"\"\n",
    "    cont_features = {}\n",
    "    for col in cont_feature_columns:\n",
    "        cont_features[col] = \\\n",
    "            tf.placeholder(dtype = tf.float64, shape = [None, 1], name = col)\n",
    "\n",
    "    cat_features = {}\n",
    "    for col in cat_feature_columns:\n",
    "        cat_features[col] = \\\n",
    "            tf.placeholder(dtype = tf.string, shape = [None, 1], name = col)\n",
    "    feature_placeholders = \\\n",
    "        dict(list(cont_features.items())+ list(cat_features.items()))\n",
    "    features = {column: tensor for column, tensor in feature_placeholders.items()}\n",
    "    label = None\n",
    "    return InputFnOps(features, label, feature_placeholders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "estimator_conf = RunConfig(num_cores = 1, tf_random_seed = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "      <th>x3</th>\n",
       "      <th>x4</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    x1   x2   x3   x4  y\n",
       "0  5.1  3.5  1.4  0.2  0\n",
       "1  4.9  3.0  1.4  0.2  0\n",
       "2  4.7  3.2  1.3  0.2  0\n",
       "3  4.6  3.1  1.5  0.2  0\n",
       "4  5.0  3.6  1.4  0.2  0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load iris data\n",
    "(X, y) = load_iris(return_X_y=True)\n",
    "iris_df = pd.DataFrame(X)\n",
    "features = ['x1', 'x2', 'x3', 'x4']\n",
    "iris_df.columns = features\n",
    "iris_df['y'] = y\n",
    "iris_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def _generate_tf_model(iris_df, features, estimator, model_output_path):\n",
    "    iris_feature_columns = features\n",
    "    def __iris_input_fn():\n",
    "        return _input_fn(iris_df, iris_feature_columns, [], label_column=\"y\")\n",
    "\n",
    "    def __iris_serving_input_fn():\n",
    "        return _serving_input_fn(iris_feature_columns, [])\n",
    "\n",
    "    estimator.fit(input_fn = __iris_input_fn, max_steps = 10)\n",
    "    _export_tf_model(estimator, __iris_serving_input_fn, model_output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def _iris_dnn_features(features):\n",
    "        \"\"\" get iris dnn features\n",
    "        \"\"\"\n",
    "        return _dnn_feature_columns(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using temporary folder as model directory: /var/folders/1_/4_crrbzx2llc_qzmrngr4vx00000gn/T/tmp_Mktml\n",
      "WARNING: 17-12-28 16:48:32: tf_logging.py:90 * 140735235661824 Using temporary folder as model directory: /var/folders/1_/4_crrbzx2llc_qzmrngr4vx00000gn/T/tmp_Mktml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: 17-12-28 16:48:32: tf_logging.py:90 * 140735235661824 Using temporary folder as model directory: /var/folders/1_/4_crrbzx2llc_qzmrngr4vx00000gn/T/tmp_Mktml\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using config: {'_save_checkpoints_secs': 600, '_num_ps_replicas': 0, '_keep_checkpoint_max': 5, '_task_type': None, '_is_chief': True, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x1c1476ec50>, '_model_dir': '/var/folders/1_/4_crrbzx2llc_qzmrngr4vx00000gn/T/tmp_Mktml', '_save_checkpoints_steps': None, '_keep_checkpoint_every_n_hours': 10000, '_session_config': None, '_tf_random_seed': 42, '_save_summary_steps': 100, '_environment': 'local', '_num_worker_replicas': 0, '_task_id': 0, '_log_step_count_steps': 100, '_tf_config': intra_op_parallelism_threads: 1\n",
      "inter_op_parallelism_threads: 1\n",
      "gpu_options {\n",
      "  per_process_gpu_memory_fraction: 1\n",
      "}\n",
      ", '_evaluation_master': '', '_master': ''}\n",
      "INFO: 17-12-28 16:48:32: tf_logging.py:82 * 140735235661824 Using config: {'_save_checkpoints_secs': 600, '_num_ps_replicas': 0, '_keep_checkpoint_max': 5, '_task_type': None, '_is_chief': True, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x1c1476ec50>, '_model_dir': '/var/folders/1_/4_crrbzx2llc_qzmrngr4vx00000gn/T/tmp_Mktml', '_save_checkpoints_steps': None, '_keep_checkpoint_every_n_hours': 10000, '_session_config': None, '_tf_random_seed': 42, '_save_summary_steps': 100, '_environment': 'local', '_num_worker_replicas': 0, '_task_id': 0, '_log_step_count_steps': 100, '_tf_config': intra_op_parallelism_threads: 1\n",
      "inter_op_parallelism_threads: 1\n",
      "gpu_options {\n",
      "  per_process_gpu_memory_fraction: 1\n",
      "}\n",
      ", '_evaluation_master': '', '_master': ''}\n",
      "WARNING:tensorflow:From /Users/lgrcyanny/anaconda2/lib/python2.7/site-packages/tensorflow/contrib/learn/python/learn/estimators/dnn.py:192: get_global_step (from tensorflow.contrib.framework.python.ops.variables) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please switch to tf.train.get_global_step\n",
      "WARNING: 17-12-28 16:48:32: tf_logging.py:90 * 140735235661824 From /Users/lgrcyanny/anaconda2/lib/python2.7/site-packages/tensorflow/contrib/learn/python/learn/estimators/dnn.py:192: get_global_step (from tensorflow.contrib.framework.python.ops.variables) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please switch to tf.train.get_global_step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: 17-12-28 16:48:32: tf_logging.py:90 * 140735235661824 From /Users/lgrcyanny/anaconda2/lib/python2.7/site-packages/tensorflow/contrib/learn/python/learn/estimators/dnn.py:192: get_global_step (from tensorflow.contrib.framework.python.ops.variables) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please switch to tf.train.get_global_step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO: 17-12-28 16:48:33: tf_logging.py:82 * 140735235661824 Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Saving checkpoints for 1 into /var/folders/1_/4_crrbzx2llc_qzmrngr4vx00000gn/T/tmp_Mktml/model.ckpt.\n",
      "INFO: 17-12-28 16:48:36: tf_logging.py:82 * 140735235661824 Saving checkpoints for 1 into /var/folders/1_/4_crrbzx2llc_qzmrngr4vx00000gn/T/tmp_Mktml/model.ckpt.\n",
      "INFO:tensorflow:loss = 1.2028, step = 1\n",
      "INFO: 17-12-28 16:48:37: tf_logging.py:82 * 140735235661824 loss = 1.2028, step = 1\n",
      "INFO:tensorflow:Saving checkpoints for 10 into /var/folders/1_/4_crrbzx2llc_qzmrngr4vx00000gn/T/tmp_Mktml/model.ckpt.\n",
      "INFO: 17-12-28 16:48:37: tf_logging.py:82 * 140735235661824 Saving checkpoints for 10 into /var/folders/1_/4_crrbzx2llc_qzmrngr4vx00000gn/T/tmp_Mktml/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 1.16411.\n",
      "INFO: 17-12-28 16:48:37: tf_logging.py:82 * 140735235661824 Loss for final step: 1.16411.\n",
      "INFO:tensorflow:Restoring parameters from /var/folders/1_/4_crrbzx2llc_qzmrngr4vx00000gn/T/tmp_Mktml/model.ckpt-10\n",
      "INFO: 17-12-28 16:48:38: tf_logging.py:82 * 140735235661824 Restoring parameters from /var/folders/1_/4_crrbzx2llc_qzmrngr4vx00000gn/T/tmp_Mktml/model.ckpt-10\n",
      "INFO:tensorflow:Assets added to graph.\n",
      "INFO: 17-12-28 16:48:38: tf_logging.py:82 * 140735235661824 Assets added to graph.\n",
      "INFO:tensorflow:No assets to write.\n",
      "INFO: 17-12-28 16:48:38: tf_logging.py:82 * 140735235661824 No assets to write.\n",
      "INFO:tensorflow:SavedModel written to: /var/folders/1_/4_crrbzx2llc_qzmrngr4vx00000gn/T/tmpnpDToR/temp-1514450917/saved_model.pbtxt\n",
      "INFO: 17-12-28 16:48:39: tf_logging.py:82 * 140735235661824 SavedModel written to: /var/folders/1_/4_crrbzx2llc_qzmrngr4vx00000gn/T/tmpnpDToR/temp-1514450917/saved_model.pbtxt\n",
      "INFO: 17-12-28 16:48:39: <ipython-input-2-3f00701a225c>:10 * 140735235661824 moving model path from /var/folders/1_/4_crrbzx2llc_qzmrngr4vx00000gn/T/tmpnpDToR/1514450917 to /tmp/pmml-models/tensorflow/dnn_classifier\n"
     ]
    }
   ],
   "source": [
    "# Train with DNNClassifier model\n",
    "algorithm_name = \"dnn_classifier\"\n",
    "base_path = \"/tmp/pmml-models/tensorflow/\"\n",
    "model_output = os.path.join(base_path, algorithm_name)\n",
    "classifier = DNNClassifier(\n",
    "    hidden_units = [4 * 3, 2 * 3],\n",
    "    feature_columns = _iris_dnn_features(features),\n",
    "    n_classes = 3, optimizer = tf.train.AdamOptimizer,\n",
    "    config = estimator_conf)\n",
    "_generate_tf_model(iris_df, features, classifier, model_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Export PMML File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: 17-12-28 16:48:39: base_converter.py:89 * 140735235661824 Starting to convert model file /tmp/pmml-models/tensorflow/dnn_classifier to pmml file\n",
      "INFO: 17-12-28 16:48:42: base_converter.py:96 * 140735235661824 Successfully generate pmml file: /tmp/pmml-models/tensorflow/dnn_classifier.pmml\n"
     ]
    }
   ],
   "source": [
    "pmml_output = os.path.join(base_path, \"{}.pmml\".format(algorithm_name))\n",
    "ppmml.to_pmml(\n",
    "    model_input=model_output,\n",
    "    pmml_output=pmml_output,\n",
    "    model_type='tensorflow')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict with PMML File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# prepare test data\n",
    "test_data_input = os.path.join(base_path, \"test.csv\")\n",
    "iris_df.to_csv(test_data_input, index=False, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: 17-12-28 16:48:42: evaluator.py:62 * 140735235661824 Starting to make predictions of pmml file: /tmp/pmml-models/tensorflow/dnn_classifier.pmml, data_input: /tmp/pmml-models/tensorflow/test.csv, data_output: /tmp/pmml-models/tensorflow/dnn_classifier.csv\n",
      "INFO: 17-12-28 16:48:43: evaluator.py:80 * 140735235661824 Successfully generate predictions to path: /tmp/pmml-models/tensorflow/dnn_classifier.csv\n"
     ]
    }
   ],
   "source": [
    "data_output = os.path.join(base_path, \"{}.csv\".format(algorithm_name))\n",
    "ppmml.predict(pmml_output, test_data_input, data_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "      <th>x3</th>\n",
       "      <th>x4</th>\n",
       "      <th>y</th>\n",
       "      <th>_target</th>\n",
       "      <th>probability(0)</th>\n",
       "      <th>probability(1)</th>\n",
       "      <th>probability(2)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.269455</td>\n",
       "      <td>0.401700</td>\n",
       "      <td>0.328845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.285334</td>\n",
       "      <td>0.384116</td>\n",
       "      <td>0.330550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.276925</td>\n",
       "      <td>0.393353</td>\n",
       "      <td>0.329722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.270846</td>\n",
       "      <td>0.400135</td>\n",
       "      <td>0.329019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.263683</td>\n",
       "      <td>0.408243</td>\n",
       "      <td>0.328074</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    x1   x2   x3   x4  y  _target  probability(0)  probability(1)  \\\n",
       "0  5.1  3.5  1.4  0.2  0        1        0.269455        0.401700   \n",
       "1  4.9  3.0  1.4  0.2  0        1        0.285334        0.384116   \n",
       "2  4.7  3.2  1.3  0.2  0        1        0.276925        0.393353   \n",
       "3  4.6  3.1  1.5  0.2  0        1        0.270846        0.400135   \n",
       "4  5.0  3.6  1.4  0.2  0        1        0.263683        0.408243   \n",
       "\n",
       "   probability(2)  \n",
       "0        0.328845  \n",
       "1        0.330550  \n",
       "2        0.329722  \n",
       "3        0.329019  \n",
       "4        0.328074  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv(data_output).head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
